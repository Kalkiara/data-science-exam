{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of years and months\n",
    "years = list(range(1960, 2023))\n",
    "months = list(range(1, 13))\n",
    "\n",
    "# initialize the list of URLs\n",
    "urls = []\n",
    "\n",
    "# loop over the years and months and create URLs\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        url = f'https://www.billboard.com/charts/hot-100/{year:04d}-{month:02d}-01/' # using year and month formatting \n",
    "        urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store each song and its corresponding URL\n",
    "song_url_dict = {}\n",
    "\n",
    "for url in urls:\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, \"html.parser\")\n",
    "\n",
    "    # get song 1\n",
    "    topSong = soup.find(\"a\", {\"href\": \"#\",\n",
    "                            \"class\": \"c-title__link lrv-a-unstyle-link\"})\n",
    "\n",
    "    # add to dictionary and remove linebreak characters\n",
    "    song_name = topSong.text.strip().replace('\\n', '')\n",
    "    song_url_dict[song_name] = url\n",
    "\n",
    "    # get songs 2-100\n",
    "    song = soup.findAll(\"h3\", {\"class\": \"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size\"\n",
    "                                        \"-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max \"\n",
    "                                        \"a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\",\n",
    "                            \"id\": \"title-of-a-story\"})\n",
    "\n",
    "    # add to dictionary and remove linebreak characters\n",
    "    for i in range(99):\n",
    "        try:\n",
    "            song_name = song[i].text.strip().replace('\\n', '')\n",
    "        except IndexError:\n",
    "            song_name = 'could_not_find'\n",
    "        song_url_dict[song_name] = url\n",
    "\n",
    "# remove the missing key-value pair \n",
    "removed_value = song_url_dict.pop('could_not_find') # 1 song from march 1977 https://www.billboard.com/charts/hot-100/1977-03-01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary to not have to rerun the scrape\n",
    "with open(\"song_url_dict.json\", \"w\") as file:\n",
    "    json.dump(song_url_dict, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dictionary\n",
    "with open(\"song_url_dict.json\", \"r\") as file:\n",
    "    song_url_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a requests session\n",
    "session = requests.Session()\n",
    "\n",
    "# set up credentials\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "\n",
    "# create the Spotify client\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager, requests_session=session)\n",
    "\n",
    "audio_features = []\n",
    "song_names = []\n",
    "urls = []\n",
    "\n",
    "for song_name, url in song_url_dict.items(): # for each song name and url\n",
    "    \n",
    "    # track the number of retries\n",
    "    retries = 0\n",
    "    \n",
    "    # make the API request and retry up to 3 times if a ReadTimeout error occurs\n",
    "    while True:\n",
    "        try:\n",
    "            results = sp.search(q=song_name, type='track', limit=1)\n",
    "            break\n",
    "        except requests.exceptions.ReadTimeout as e:\n",
    "            if retries < 3:\n",
    "                retries += 1\n",
    "                print(f'ReadTimeout error encountered for \"{song_name}\". Retrying in 5 seconds (retry {retries}/3)')\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(f'ReadTimeout error encountered for \"{song_name}\". Maximum retries reached. Skipping.')\n",
    "                break\n",
    "\n",
    "    if results['tracks']['total'] > 0:\n",
    "        track_id = results['tracks']['items'][0]['id']\n",
    "        \n",
    "        # make the API request and retry up to 3 times if a ReadTimeout error occurs\n",
    "        retries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                features = sp.audio_features(track_id)[0]\n",
    "                break\n",
    "            except requests.exceptions.ReadTimeout as e:\n",
    "                if retries < 3:\n",
    "                    retries += 1\n",
    "                    print(f'ReadTimeout error encountered for \"{song_name}\". Retrying in 5 seconds (retry {retries}/3)')\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(f'ReadTimeout error encountered for \"{song_name}\". Maximum retries reached. Skipping.')\n",
    "                    break\n",
    "        \n",
    "        # check if features is None before appending to list\n",
    "        if features is not None:\n",
    "            audio_features.append(features)\n",
    "            song_names.append(song_name)\n",
    "            urls.append(url)\n",
    "\n",
    "# convert features to a dataframe\n",
    "df = pd.DataFrame(audio_features)\n",
    "\n",
    "# add relevant columns to the dataframe\n",
    "df['song_name'] = song_names\n",
    "df['scraped_url'] = urls\n",
    "\n",
    "# extract date from URL and add to new column\n",
    "df['date'] = df['scraped_url'].apply(lambda x: x.split('/')[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save as csv\n",
    "outfile = os.path.join(\"..\", \"data\", \"top_songs_by_month.csv\") # point to data location\n",
    "df.to_csv(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ea50ce4b5898576252dc62ba6e93b2c3a4b2c43c01e45709956491a2c02e21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
